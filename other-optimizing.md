# Other Optimizing

Trying to make other people better.

[[Eliezer Yudkowsky]] poses this could be bad if you don't understand the deep enough rules beneath whatever change you manifested. It may not apply to the person you're trying to other optimise. 

[[Choice Theory]] suggests this could be bad as other-optimising restricts the other persons capability of choice.

[[Leaf]] has thoughts on this that mostly align with [[choice theory]].


https://threadreaderapp.com/thread/1274859897826488322.html?refreshed=yes
think a lot about this thread in relation to that

basicawlly fofr systems that push abck (like people) it is hard to other optimie because you can't give step process and expect it to work

how could you get around that issue and create more adaptable people changing systems?

(Metaphor: [[Increasing the Funnel]])





[//begin]: # "Autogenerated link references for markdown compatibility"
[Eliezer Yudkowsky]: eliezer-yudkowsky "Eliezer Yudkowsky"
[Choice Theory]: choice-theory "Choice Theory"
[Leaf]: leaf "Leaf"
[choice theory]: choice-theory "Choice Theory"
[Increasing the Funnel]: increasing-the-funnel "Increasing the Funnel"
[//end]: # "Autogenerated link references"